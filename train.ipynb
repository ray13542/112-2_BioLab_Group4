{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"f58c1610-c5e0-418f-9cd3-ad78b73850d1","_uuid":"67395f75-bbaf-4b08-91f5-2b00147edfc0","trusted":true},"source":["# Data readin and pre-processing"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6bf032b7-e904-4079-816b-3ab4c485261f","_uuid":"225ffed2-2218-4e89-9a0e-7ba76fdc0565","collapsed":false,"execution":{"iopub.execute_input":"2024-05-22T05:28:43.724897Z","iopub.status.busy":"2024-05-22T05:28:43.724510Z","iopub.status.idle":"2024-05-22T05:28:46.207492Z","shell.execute_reply":"2024-05-22T05:28:46.206017Z","shell.execute_reply.started":"2024-05-22T05:28:43.724865Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import os\n","import numpy as np\n","from scipy import signal\n","\n","def process_csv(file_path, freq1=20, freq2=450, fs=1000, process_method='bp'):\n","    \"\"\"\n","    read the csv file and process the data\n","    :param file_path: the path of the csv file\n","    :param freq1: the lower bound of the bandpass filter\n","    :param freq2: the upper bound of the bandpass filter\n","    :param fs: the sampling rate\n","    :return: the processed data\n","    \"\"\"\n","\n","    df = pd.read_csv(file_path)\n","    \n","    data1 = df.iloc[:, 1]\n","    data2 = df.iloc[:, 2]\n","    if process_method == 'raw_data':\n","        processed_df = pd.DataFrame({\n","            'EMG1': data1,\n","            'EMG2': data2,\n","            'class': df.iloc[:, 3]\n","        })\n","    elif process_method == 'bp':\n","        # filter the data with a bandpass filter\n","        b, a = signal.butter(4, [freq1, freq2], 'bandpass', fs=fs)\n","        data1 = signal.filtfilt(b, a, data1)\n","        data2 = signal.filtfilt(b, a, data2)\n","        processed_df = pd.DataFrame({\n","        'EMG1': data1,\n","        'EMG2': data2,\n","        'class': df.iloc[:, 3]\n","    })\n","    elif process_method == 'sma':\n","        # SMA\n","        SMA1 = np.zeros(len(data1) - 50)\n","        SMA2 = np.zeros(len(data2) - 50)\n","        for i in range(len(data1) - 50):\n","            SMA1[i] = np.mean(data1[i:i + 51])\n","            SMA2[i] = np.mean(data2[i:i + 51])\n","\n","        processed_df = pd.DataFrame({\n","            'EMG1': data1[50:],\n","            'EMG2': data2[50:],\n","            'SMA1': SMA1,\n","            'SMA2': SMA2,\n","            'class': df.iloc[50:, 3]\n","        })\n","    elif process_method == 'bp+rms':\n","        # filter the data with a bandpass filter\n","        b, a = signal.butter(4, [freq1, freq2], 'bandpass', fs=fs)\n","        data1_bp = signal.filtfilt(b, a, data1)\n","        data2_bp = signal.filtfilt(b, a, data2)\n","\n","        # calculate the RMS\n","        RMS1 = np.zeros(len(data1_bp)-50)\n","        RMS2 = np.zeros(len(data2_bp)-50)\n","        \n","        for i in range(len(data1_bp)-50):\n","            RMS1[i] = np.sqrt(np.mean(data1_bp[i:i+51]**2))\n","            RMS2[i] = np.sqrt(np.mean(data2_bp[i:i+51]**2))\n","        \n","        processed_df = pd.DataFrame({\n","            'EMG1': RMS1,\n","            'EMG2': RMS2,\n","            'class': df.iloc[50:, 3]\n","        })\n","    elif process_method == 'bp+sma':\n","        # filter the data with a bandpass filter\n","        b, a = signal.butter(4, [freq1, freq2], 'bandpass', fs=fs)\n","        data1_bp = signal.filtfilt(b, a, data1)\n","        data2_bp = signal.filtfilt(b, a, data2)\n","        \n","        # SMA\n","        SMA1 = np.zeros(len(data1_bp) - 50)\n","        SMA2 = np.zeros(len(data2_bp) - 50)\n","        for i in range(len(data1_bp) - 50):\n","            SMA1[i] = np.mean(data1_bp[i:i + 51])\n","            SMA2[i] = np.mean(data2_bp[i:i + 51])\n","        processed_df = pd.DataFrame({\n","            'SMA1': SMA1,\n","            'SMA2': SMA2,\n","            'class': df.iloc[50:, 3]\n","        })\n","    elif process_method == 'bp+rms+sma':\n","        # filter the data with a bandpass filter\n","        b, a = signal.butter(4, [freq1, freq2], 'bandpass', fs=fs)\n","        data1_bp = signal.filtfilt(b, a, data1)\n","        data2_bp = signal.filtfilt(b, a, data2)\n","\n","        # calculate the RMS\n","        RMS1 = np.zeros(len(data1_bp) - 50)\n","        RMS2 = np.zeros(len(data2_bp) - 50)\n","\n","        for i in range(len(data1_bp) - 50):\n","            RMS1[i] = np.sqrt(np.mean(data1_bp[i:i + 51] ** 2))\n","            RMS2[i] = np.sqrt(np.mean(data2_bp[i:i + 51] ** 2))\n","\n","        # SMA\n","        SMA1 = np.zeros(len(RMS1) - 50)\n","        SMA2 = np.zeros(len(RMS2) - 50)\n","        for i in range(len(RMS1) - 50):\n","            SMA1[i] = np.mean(RMS1[i:i + 51])\n","            SMA2[i] = np.mean(RMS2[i:i + 51])\n","\n","        processed_df = pd.DataFrame({\n","            'SMA1': SMA1,\n","            'SMA2': SMA2,\n","            'class': df.iloc[100:, 3]\n","        })\n","    \n","    return processed_df"]},{"cell_type":"markdown","metadata":{"_cell_guid":"ad80ad89-af77-4180-bdfb-9ab2ee3156c8","_uuid":"9b13fe39-0772-4100-9eb7-70ba36c1e503","trusted":true},"source":["# Sliding windows"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8eccf8fe-7616-469f-ad9d-1619cc169566","_uuid":"91abfd16-6d44-4734-8095-143a352268ff","collapsed":false,"execution":{"iopub.execute_input":"2024-05-22T05:28:46.258883Z","iopub.status.busy":"2024-05-22T05:28:46.257911Z","iopub.status.idle":"2024-05-22T05:28:46.271866Z","shell.execute_reply":"2024-05-22T05:28:46.270393Z","shell.execute_reply.started":"2024-05-22T05:28:46.258833Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def sliding_window(data, window_size, stride):\n","    \"\"\"\n","    对数据应用滑动窗口处理。\n","    \n","    参数:\n","    data (pd.DataFrame): 输入的数据。\n","    window_size (int): 窗口大小。\n","    stride (int): 滑动步幅。\n","    \n","    返回:\n","    np.ndarray: 滑动窗口处理后的数据。\n","    np.ndarray: 滑动窗口对应的标签。\n","    \"\"\"\n","    windowed_data = []\n","    labels = []\n","\n","    for i in range(0, len(data) - window_size + 1, stride):\n","        windowed = data.iloc[i:i + window_size, :-1].values  # Exclude label column and convert to NumPy array\n","        label_window = data.iloc[i:i + window_size, -1]  # Get all labels in the window\n","        labels.append(label_window.value_counts().idxmax())\n","        windowed_data.append(windowed)\n","        # if len(label_window.unique()) == 1:  # Check if all labels in the window are the same\n","        #     windowed_data.append(windowed)\n","        #     labels.append(label_window.iloc[0])  # Use the first label as the label for the window\n","\n","    return np.array(windowed_data), np.array(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b28edcad-c222-4f8a-8d23-f24014180b2c","_uuid":"bcdd586b-aa1b-4552-aa85-832e1420c8c6","collapsed":false,"execution":{"iopub.execute_input":"2024-05-22T05:28:46.273559Z","iopub.status.busy":"2024-05-22T05:28:46.273122Z","iopub.status.idle":"2024-05-22T05:29:38.739265Z","shell.execute_reply":"2024-05-22T05:29:38.737709Z","shell.execute_reply.started":"2024-05-22T05:28:46.273527Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# 主程序\n","folder_path = \"./0527data/\"\n","csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n","\n","freq1 = 100\n","freq2 = 400\n","window_size = 3000\n","stride = 200\n","method = 'raw_data'\n","\n","\n","# 初始化滑动窗口处理后的数据和标签列表\n","windowed_data_all = []\n","labels_all = []\n","\n","# 逐个文件处理数据并应用滑动窗口\n","for file in csv_files:\n","    file_path = os.path.join(folder_path, file)\n","    processed_df = process_csv(file_path, freq1, freq2, process_method=method)\n","    # windowed_data, labels = sliding_window(processed_df.drop('time', axis=1), window_size, stride) \n","    windowed_data, labels = sliding_window(processed_df, window_size, stride)\n","    windowed_data_all.append(windowed_data)\n","    labels_all.append(labels)\n","\n","# 将所有滑动窗口处理后的数据和标签合并\n","windowed_data_all = np.concatenate(windowed_data_all, axis=0)\n","labels_all = np.concatenate(labels_all, axis=0)\n","labels_all = labels_all - 1\n","\n","# 示例: 显示滑动窗口处理后的数据和标签的形状\n","print(\"滑动窗口处理后的数据形状:\", windowed_data_all.shape)\n","print(\"滑动窗口处理后的标签形状:\", labels_all.shape)\n","print(windowed_data_all[0:1])\n","print(labels_all[0:5])"]},{"cell_type":"markdown","metadata":{},"source":["# Model: CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T05:29:38.748963Z","iopub.status.busy":"2024-05-22T05:29:38.748586Z","iopub.status.idle":"2024-05-22T05:29:39.015754Z","shell.execute_reply":"2024-05-22T05:29:39.014483Z","shell.execute_reply.started":"2024-05-22T05:29:38.748935Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(windowed_data_all, labels_all\n","                                                    , test_size=0.20, random_state=42)\n","print(X_train.shape)\n","print(X_train[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T05:29:39.020407Z","iopub.status.busy":"2024-05-22T05:29:39.019988Z","iopub.status.idle":"2024-05-22T05:29:54.521343Z","shell.execute_reply":"2024-05-22T05:29:54.520020Z","shell.execute_reply.started":"2024-05-22T05:29:39.020376Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Input\n","\n","def CNN_model(input_shape, num_classes):\n","    model = Sequential()\n","\n","    model.add(Input(shape=input_shape))\n","\n","    # Convolutional layers\n","    model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n","    model.add(MaxPooling1D(pool_size=2))\n","\n","    model.add(Conv1D(64, kernel_size=3, activation='relu'))\n","    model.add(MaxPooling1D(pool_size=2))\n","\n","    # Flattening layers\n","    model.add(Flatten())\n","\n","    # Full connected layers\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dense(num_classes, activation='softmax'))\n","\n","    # compile the model\n","    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T05:29:54.524614Z","iopub.status.busy":"2024-05-22T05:29:54.523189Z","iopub.status.idle":"2024-05-22T05:29:54.736500Z","shell.execute_reply":"2024-05-22T05:29:54.735144Z","shell.execute_reply.started":"2024-05-22T05:29:54.524563Z"},"trusted":true},"outputs":[],"source":["# define the CNN model\n","input_shape = X_train.shape[1:]  # set input size\n","num_classes = len(np.unique(y_train))   # set class size\n","\n","model = CNN_model(input_shape, num_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T05:29:54.738309Z","iopub.status.busy":"2024-05-22T05:29:54.737911Z","iopub.status.idle":"2024-05-22T05:31:37.100372Z","shell.execute_reply":"2024-05-22T05:31:37.099291Z","shell.execute_reply.started":"2024-05-22T05:29:54.738277Z"},"trusted":true},"outputs":[],"source":["history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T05:31:37.104931Z","iopub.status.busy":"2024-05-22T05:31:37.103853Z","iopub.status.idle":"2024-05-22T05:31:40.797954Z","shell.execute_reply":"2024-05-22T05:31:40.796554Z","shell.execute_reply.started":"2024-05-22T05:31:37.104891Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import accuracy_score, f1_score\n","\n","# make predictions on training data\n","y_pred_train = model.predict(X_train)\n","y_pred_train = np.argmax(y_pred_train, axis=1)  # Convert from one-hot encoding to tags\n","\n","# make predictions on test data\n","y_pred_test = model.predict(X_test)\n","y_pred_test = np.argmax(y_pred_test, axis=1)  # Convert from one-hot encoding to tags\n","\n","# calculate accuracy\n","accuracy_training = accuracy_score(y_train, y_pred_train)\n","accuracy_test = accuracy_score(y_test, y_pred_test)\n","\n","# calculate F1 score\n","f1_training = f1_score(y_train, y_pred_train, average='weighted')\n","f1_test = f1_score(y_test, y_pred_test, average='weighted')\n","\n","print(\"Training Accuracy:\", accuracy_training)\n","print(\"Test Accuracy:\", accuracy_test)\n","print(\"Training F1 Score:\", f1_training)\n","print(\"Test F1 Score:\", f1_test)\n","\n","#write in an csv to save the result with frequency1, frequency2, window_size, stride, processing method\n","#dont overwrite the file\n","#we need to write in a new row\n","\n","import csv\n","\n","with open('./models/result.csv', mode='a') as file:\n","    writer = csv.writer(file)\n","    writer.writerow([freq1, freq2, window_size, stride, method, accuracy_training, accuracy_test, f1_training, f1_test])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T05:31:40.799706Z","iopub.status.busy":"2024-05-22T05:31:40.799338Z","iopub.status.idle":"2024-05-22T05:31:41.110815Z","shell.execute_reply":"2024-05-22T05:31:41.109506Z","shell.execute_reply.started":"2024-05-22T05:31:40.799675Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","# training and testing loss graph\n","plt.plot(history.history['loss'], label='Training loss')\n","plt.plot(history.history['val_loss'], label='Test Loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T05:31:41.112911Z","iopub.status.busy":"2024-05-22T05:31:41.112547Z","iopub.status.idle":"2024-05-22T05:31:41.731560Z","shell.execute_reply":"2024-05-22T05:31:41.730137Z","shell.execute_reply.started":"2024-05-22T05:31:41.112880Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","\n","cm = confusion_matrix(y_test, y_pred_test)\n","plt.figure(figsize=(6, 6))\n","sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n","plt.title('Confusion Matrix SW')\n","plt.xlabel('Predicted Labels SW')\n","plt.ylabel('Real Labels SW')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import classification_report\n","\n","# accuracy and F1 score of classes\n","rapor = classification_report(y_test, y_pred_test, target_names=[str(i) for i in np.unique(y_test)])\n","print(rapor)"]},{"cell_type":"markdown","metadata":{},"source":["# Save models"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-22T06:18:39.043967Z","iopub.status.busy":"2024-05-22T06:18:39.042832Z","iopub.status.idle":"2024-05-22T06:18:39.120981Z","shell.execute_reply":"2024-05-22T06:18:39.119383Z","shell.execute_reply.started":"2024-05-22T06:18:39.043921Z"},"trusted":true},"outputs":[],"source":["# 輸出 SavedModel 的格式來輸出模型\n","model_name = 'EMG_classification_newdata_'+ str(method) + '_' +str(freq1)+'_'+str(freq2)+'_'+str(window_size)+'.keras'\n","model.save('./models/' + model_name)"]},{"cell_type":"markdown","metadata":{},"source":["# Predict hidden"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","new_model = tf.keras.models.load_model('./models/' + model_name)\n","\n","# Show the model architecture\n","new_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["folder_path = \"./0520hidden/\"\n","csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n","\n","\n","# 初始化滑动窗口处理后的数据和标签列表\n","data_hidden = []\n","labels_hidden = []\n","\n","# 逐个文件处理数据并应用滑动窗口\n","for file in csv_files:\n","    file_path = os.path.join(folder_path, file)\n","    processed_df = process_csv(file_path, freq1, freq2, process_method=method)\n","    windowed_data, labels = sliding_window(processed_df, window_size, stride)\n","    data_hidden.append(windowed_data)\n","    labels_hidden.append(labels)\n","\n","# 将所有滑动窗口处理后的数据和标签合并\n","data_hidden = np.concatenate(data_hidden, axis=0)\n","labels_hidden = np.concatenate(labels_hidden, axis=0)\n","\n","print(data_hidden.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["label_pred = new_model.predict(data_hidden)\n","label_pred = np.argmax(label_pred, axis=1)  # Convert from one-hot encoding to tags\n","\n","\n","# calculate accuracy\n","hidden_accuracy = accuracy_score(labels_hidden, label_pred)\n","\n","# calculate F1 score\n","hidden_1 = f1_score(labels_hidden, label_pred, average='weighted')\n","print(\"Training Accuracy:\", hidden_accuracy)\n","print(\"Training F1 Score:\", hidden_1)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5052767,"sourceId":8473392,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":4}
